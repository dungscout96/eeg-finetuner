foundation_model:
  embedding_size: 128
  input_size: 128
  model_name: labram
  num_channels: 64
freeze_backbone: true
learning_rate: 0.001
task:
  decoder_type: linear
  input_size: 128
  num_classes: 2
  task_type: classification
